<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Artifact 4 - Data Challenge Scenarios: Addressing Real-World ML Data Issues</title>
<style>
  /* Reset & Base Styles */
  * {
    box-sizing: border-box;
  }
  body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    margin: 0;
    padding: 0;
    background-color: #f8fafb;
    color: #333;
    line-height: 1.65;
  }
  a {
    color: #0077cc;
    text-decoration: none;
  }
  a:hover {
    text-decoration: underline;
  }
  h1, h2, h3, h4, h5 {
    margin-top: 0;
    color: #0b3d91;
  }
  h1 {
    font-size: 3rem;
    margin-bottom: 0.5rem;
  }
  h2 {
    font-size: 2.4rem;
    margin-top: 2rem;
    margin-bottom: 1rem;
    border-bottom: 3px solid #f5a623;
    padding-bottom: 0.2rem;
  }
  h3 {
    font-size: 1.9rem;
    margin-top: 1.8rem;
    margin-bottom: 0.8rem;
    color: #2c9e4f;
  }
  p {
    max-width: 900px;
    margin: 0 0 1rem 0;
    font-size: 1.15rem;
  }
  ul, ol {
    max-width: 900px;
    margin: 0 0 1rem 2rem;
    font-size: 1.1rem;
  }
  ul li, ol li {
    margin-bottom: 0.6rem;
  }
  pre {
    background-color: #1e293b;
    color: #f8fafc;
    padding: 15px;
    border-radius: 8px;
    max-width: 900px;
    overflow-x: auto;
    font-family: 'Courier New', Courier, monospace;
    font-size: 1rem;
    margin: 1.5rem 0 2.5rem 0;
  }
  blockquote {
    border-left: 5px solid #f5a623;
    padding-left: 1rem;
    font-style: italic;
    color: #555;
    max-width: 900px;
    margin: 2rem 0;
    background-color: #fff8e1;
  }
  header, footer {
    background-color: #0b3d91;
    color: white;
    padding: 1rem 2rem;
    position: sticky;
    top: 0;
    z-index: 1000;
    box-shadow: 0 2px 5px rgba(0,0,0,0.2);
  }
  nav {
    display: flex;
    justify-content: space-between;
    align-items: center;
    max-width: 1200px;
    margin: 0 auto;
  }
  nav .logo {
    font-weight: 700;
    font-size: 1.8rem;
    color: #f5a623;
  }
  nav ul {
    list-style: none;
    display: flex;
    gap: 1.5rem;
  }
  nav ul li a {
    color: white;
    font-weight: 600;
    padding: 0.5rem 0.8rem;
    border-radius: 4px;
    transition: background-color 0.3s ease;
  }
  nav ul li a:hover,
  nav ul li a.active {
    background-color: #f5a623;
    color: #0b3d91;
  }
  main {
    max-width: 900px;
    margin: 2rem auto 4rem auto;
    background-color: white;
    padding: 2rem 3rem;
    border-radius: 12px;
    box-shadow: 0 10px 30px rgba(0,0,0,0.05);
  }
  footer {
    text-align: center;
    font-size: 0.9rem;
  }
  /* Responsive Design */
  @media (max-width: 768px) {
    main {
      padding: 1.5rem 1.5rem;
      margin: 1rem;
    }
    nav ul {
      flex-direction: column;
      gap: 0.5rem;
    }
  }
</style>
</head>
<body>

<header role="banner" aria-label="Primary Navigation">
  <nav role="navigation" aria-label="Main menu">
    <div class="logo" tabindex="0">Naga Venkata Satyanarayana Devarapalli</div>
    <ul role="menubar" aria-label="Primary Navigation Menu">
      <li role="none"><a href="../index.html" role="menuitem" tabindex="0">Home</a></li>
      <li role="none"><a href="../bio.html" role="menuitem" tabindex="0">Bio</a></li>
      <li role="none"><a href="artifact1.html" role="menuitem" tabindex="0">Artifact 1</a></li>
      <li role="none"><a href="artifact2.html" role="menuitem" tabindex="0">Artifact 2</a></li>
      <li role="none"><a href="artifact3.html" role="menuitem" tabindex="0">Artifact 3</a></li>
      <li role="none"><a href="artifact4.html" role="menuitem" tabindex="0" class="active">Artifact 4</a></li>
      <li role="none"><a href="artifact5.html" role="menuitem" tabindex="0">Artifact 5</a></li>
    </ul>
  </nav>
</header>

<main role="main" tabindex="0" aria-label="Artifact 4 Content">

  <h1>Artifact 4: Data Challenge Scenarios – Navigating Data Quality, Bias, and Privacy in Machine Learning</h1>

  <section aria-label="Objective">
    <h2>Objective</h2>
    <p>
      The primary goal of this artifact is to demonstrate my ability to identify, analyze, and resolve critical data challenges encountered in real-world machine learning workflows. These challenges include data quality issues, privacy and security concerns, and bias in AI systems. Successfully addressing these problems ensures that AI models are accurate, fair, and trustworthy.
    </p>
  </section>

  <section aria-label="Context of the Work">
    <h2>Context of the Work</h2>
    <p>
      This artifact was developed as part of Module 4: Data Challenges in Machine Learning during my Master’s coursework in Artificial Intelligence – Data Analytics at Indiana Wesleyan University. The activity required interaction with a SchoolAI Data Challenge Scenarios Coach, which presented three simulated real-world scenarios involving data preparation, privacy compliance, and bias mitigation.
    </p>
  </section>

  <section aria-label="Process and Methodology">
    <h2>Process and Methodology</h2>

    <article aria-label="Step 1: Understanding the Scenarios">
      <h3>Step 1: Understanding the Scenarios</h3>
      <p>The chatbot presented three unique scenarios:</p>
      <ul>
        <li><strong>Data Quality Issues</strong> – Missing values, duplicates, and noisy data in a financial dataset.</li>
        <li><strong>Privacy and Security</strong> – Handling sensitive healthcare data subject to GDPR and HIPAA.</li>
        <li><strong>Bias and Fairness</strong> – Addressing imbalanced datasets and algorithmic bias in predictive hiring models.</li>
      </ul>
    </article>

    <article aria-label="Step 2: Solutions for Each Scenario">
      <h3>Step 2: Solutions for Each Scenario</h3>

      <section aria-label="Scenario 1: Data Quality">
        <h4>Scenario 1: Data Quality</h4>
        <h5>Challenges Identified:</h5>
        <ul>
          <li>Missing values in key attributes.</li>
          <li>Duplicate entries affecting accuracy.</li>
          <li>Outliers creating skewed distributions.</li>
        </ul>

        <h5>Solutions Applied:</h5>
        <ul>
          <li><strong>Imputation:</strong> Used mean/mode imputation for missing numerical and categorical data.</li>
          <li><strong>Normalization:</strong> Applied Min-Max scaling to handle data distribution.</li>
          <li><strong>Outlier Treatment:</strong> Used Z-score method to identify and remove outliers.</li>
          <li><strong>Tools:</strong> Python (Pandas, NumPy), scikit-learn preprocessing functions.</li>
        </ul>

        <pre>
# Example Python code for missing data imputation and outlier removal
import pandas as pd
import numpy as np
from scipy import stats
from sklearn.preprocessing import MinMaxScaler

# Load dataset
data = pd.read_csv('financial_data.csv')

# Impute missing numerical values with mean
data['income'].fillna(data['income'].mean(), inplace=True)

# Impute missing categorical values with mode
data['occupation'].fillna(data['occupation'].mode()[0], inplace=True)

# Remove duplicates
data.drop_duplicates(inplace=True)

# Remove outliers using Z-score
z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))
data = data[(z_scores < 3).all(axis=1)]

# Normalize numerical features
scaler = MinMaxScaler()
data[['income', 'age']] = scaler.fit_transform(data[['income', 'age']])
        </pre>
      </section>

      <section aria-label="Scenario 2: Privacy and Security">
        <h4>Scenario 2: Privacy and Security</h4>
        <h5>Challenges Identified:</h5>
        <ul>
          <li>Sensitive patient data (PHI) requiring legal compliance.</li>
          <li>Potential for data breaches during transmission and storage.</li>
        </ul>

        <h5>Solutions Applied:</h5>
        <ul>
          <li><strong>Data Anonymization:</strong> Removed personal identifiers like names and IDs.</li>
          <li><strong>Encryption:</strong> Applied AES-256 for secure data storage.</li>
          <li><strong>Access Control:</strong> Implemented role-based access policies.</li>
          <li><strong>Compliance:</strong> Ensured adherence to GDPR, HIPAA, and FERPA standards.</li>
          <li><strong>Tools:</strong> Python cryptography libraries, secured cloud storage.</li>
        </ul>

        <pre>
# Example Python code for AES encryption using cryptography library
from cryptography.fernet import Fernet

# Generate key (store this securely)
key = Fernet.generate_key()
cipher_suite = Fernet(key)

# Encrypt data
sensitive_data = b"Patient PHI data to encrypt"
encrypted_data = cipher_suite.encrypt(sensitive_data)

# Decrypt data
decrypted_data = cipher_suite.decrypt(encrypted_data)
print(decrypted_data.decode())
        </pre>
      </section>

      <section aria-label="Scenario 3: Bias and Fairness">
        <h4>Scenario 3: Bias and Fairness</h4>
        <h5>Challenges Identified:</h5>
        <ul>
          <li>Class imbalance in hiring prediction dataset (e.g., 80% male candidates).</li>
          <li>Potential for gender and ethnicity-based bias in ML predictions.</li>
        </ul>

        <h5>Solutions Applied:</h5>
        <ul>
          <li><strong>Class Balancing:</strong> Used SMOTE (Synthetic Minority Oversampling Technique).</li>
          <li><strong>Bias Audit:</strong> Performed fairness evaluation using metrics such as Equal Opportunity Difference and Demographic Parity.</li>
          <li><strong>Model Recalibration:</strong> Adjusted thresholds to reduce disparate impact.</li>
          <li><strong>Team Diversity:</strong> Recommended inclusion of diverse stakeholders in model design.</li>
          <li><strong>Tools:</strong> Python (imbalanced-learn, AIF360), bias detection frameworks.</li>
        </ul>

        <pre>
# Example Python code to perform SMOTE oversampling
from imblearn.over_sampling import SMOTE
from collections import Counter
from sklearn.model_selection import train_test_split

X = data.drop('target', axis=1)
y = data['target']

print('Original dataset shape %s' % Counter(y))
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X, y)
print('Resampled dataset shape %s' % Counter(y_res))
        </pre>
      </section>
    </article>

    <article aria-label="Step 3: Documentation and Reflection">
      <h3>Step 3: Documentation and Reflection</h3>
      <p>Throughout the interaction with the SchoolAI chatbot, I recorded all decisions, evaluated the effectiveness of each solution, and noted areas for improvement. This process has been integrated as a portfolio artifact demonstrating critical thinking and applied ML knowledge.</p>

      <blockquote>
        "Handling data challenges with ethical and technical rigor is essential to build AI systems that are trustworthy and effective."
      </blockquote>

      <h4>Tools & Techniques Used</h4>
      <ul>
        <li><strong>Languages:</strong> Python</li>
        <li><strong>Libraries:</strong> Pandas, NumPy, scikit-learn, imbalanced-learn, AIF360</li>
        <li><strong>Techniques:</strong> Data preprocessing, normalization, outlier detection, SMOTE, fairness metrics</li>
        <li><strong>Security Practices:</strong> AES encryption, anonymization, GDPR/HIPAA compliance</li>
        <li><strong>Platform:</strong> SchoolAI interactive chatbot</li>
      </ul>

      <h4>Value Proposition</h4>
      <p>This artifact demonstrates my ability to:</p>
      <ul>
        <li>Diagnose and resolve data quality issues for robust ML training.</li>
        <li>Implement privacy and security measures that comply with global standards.</li>
        <li>Identify and mitigate algorithmic bias to promote ethical AI practices.</li>
      </ul>

      <h4>Professional Roles Supported</h4>
      <ul>
        <li>Machine Learning Engineer</li>
        <li>AI/ML Data Scientist</li>
        <li>Ethical AI Specialist</li>
        <li>Data Governance Analyst</li>
      </ul>
    </article>

    <article aria-label="Reflection and Feedback">
      <h3>Reflection</h3>
      <p>Engaging with the Data Challenge Scenarios reinforced the practical complexities of AI implementation. Key lessons learned include:</p>
      <ul>
        <li><strong>Data quality drives model performance:</strong> Poor data leads to flawed predictions, regardless of algorithm quality.</li>
        <li><strong>Bias originates at multiple stages:</strong> Not just in data collection but also in labeling, feature selection, and interpretation.</li>
        <li><strong>Privacy is non-negotiable:</strong> Compliance and security measures are integral to maintaining trust and preventing legal risks.</li>
      </ul>

      <h4>Feedback Integration</h4>
      <p>The chatbot feedback helped me refine my approaches, especially in handling outliers and choosing fairness metrics. Initially, I considered only accuracy metrics, but after feedback, I incorporated demographic parity checks for ethical compliance.</p>

      <h4>Customization for Audience</h4>
      <p>For my portfolio, I expanded the technical descriptions, included compliance details, and illustrated the use of bias auditing frameworks to make this artifact relevant for employers in AI ethics, data governance, and advanced ML roles.</p>

      <h4>Evidence of Learning</h4>
      <ul>
        <li>Screenshot of chatbot interaction (available in portfolio).</li>
        <li>Documentation of solutions and applied techniques.</li>
        <li>Reflection demonstrating critical thinking and ethical consideration.</li>
      </ul>
    </article>

  </section>

</main>

<footer>
  <p>&copy; 2025 Naga Venkata Satyanarayana Devarapalli | 
    <a href="../index.html">Home</a> | 
    <a href="../bio.html">Bio</a>
  </p>
</footer>

</body>
</html>
